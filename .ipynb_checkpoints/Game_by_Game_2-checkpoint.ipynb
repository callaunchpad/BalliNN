{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import commonplayerinfo, playercareerstats, leaguegamefinder, commonteamroster, leagueseasonmatchups\n",
    "from nba_api.stats.static import players, teams\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" for saving and loading things to a pickle file. Don't need to add extension to the file name \"\"\"\n",
    "def save_obj(obj, filename, dirname='pickle_files', ):\n",
    "    with open(path.join(dirname, filename + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(filename, dirname='pickle_files'):\n",
    "    with open(path.join(dirname, filename + '.pkl'), 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>nickname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>year_founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Hawks</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cavaliers</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1610612740</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Pelicans</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1610612741</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             full_name abbreviation   nickname         city  \\\n",
       "0  1610612737         Atlanta Hawks          ATL      Hawks      Atlanta   \n",
       "1  1610612738        Boston Celtics          BOS    Celtics       Boston   \n",
       "2  1610612739   Cleveland Cavaliers          CLE  Cavaliers    Cleveland   \n",
       "3  1610612740  New Orleans Pelicans          NOP   Pelicans  New Orleans   \n",
       "4  1610612741         Chicago Bulls          CHI      Bulls      Chicago   \n",
       "\n",
       "           state  year_founded  \n",
       "0        Atlanta          1949  \n",
       "1  Massachusetts          1946  \n",
       "2           Ohio          1970  \n",
       "3      Louisiana          2002  \n",
       "4       Illinois          1966  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_df = pd.DataFrame(teams.get_teams())\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ids = teams_df.loc[:, (\"id\",\"abbreviation\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' *** use pickle files for pre-saved data ***\\n\\n    - pulls the game by game data from the NBA API\\n    - store dictionary key = team abbreviation, value = df with game data '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" *** use pickle files for pre-saved data ***\n",
    "\n",
    "    - pulls the game by game data from the NBA API\n",
    "    - store dictionary key = team abbreviation, value = df with game data \"\"\"\n",
    "\n",
    "# import time\n",
    "\n",
    "# team_names = {}\n",
    "# for i in range(len(team_ids)): \n",
    "#     temp_id = team_ids[\"id\"][i]\n",
    "#     temp_team_name = team_ids[\"abbreviation\"][i]\n",
    "#     print('getting team: {0}...'.format(temp_team_name))\n",
    "#     team_names[temp_team_name] = leaguegamefinder.LeagueGameFinder(team_id_nullable=temp_id).get_data_frames()[0]\n",
    "#     time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load the team_names dictionary in pickle_files \"\"\"\n",
    "team_names = load_obj('team_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" updated teams_names dictionary where the key is team_id, value is team stats\"\"\"\n",
    "team_names_test = {}\n",
    "\n",
    "ids = team_ids[\"id\"]\n",
    "abr = team_ids[\"abbreviation\"]\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    real_value = team_names[abr[i]]\n",
    "    test_key = ids[i]\n",
    "    team_names_test[test_key] = real_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" all_abrs is a dictionary of team_names with cleaedn team_abbreviations\n",
    "    that have changed over the years\"\"\"\n",
    "\n",
    "all_abrs = {}\n",
    "for team in team_names.keys():\n",
    "    df = team_names[team]\n",
    "    abrs = set()\n",
    "    for game in df.values.tolist():\n",
    "        abrs.add(game[2])\n",
    "    for abr in abrs:\n",
    "        all_abrs[abr] = df\n",
    "        \n",
    "#all_abrs['CHA'][200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Team Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(prev_season):\n",
    "    scaler = StandardScaler()\n",
    "    season = []\n",
    "    for i in team_ids[\"id\"]:\n",
    "        teams_df = get_season_team(prev_season, i, team_names_test)\n",
    "        teams_list = teams_df.drop(teams_df.columns[list(range(0, 9))], axis = 1).values.tolist()\n",
    "        season += teams_list\n",
    "    \n",
    "    scaler.fit(season)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" gets the season games given the seasonID and abbreviation of the team \"\"\"\n",
    "\"\"\" Season is based on the year that the season STARTED in. I.E 2016-2017 has seasonID 2016\"\"\"\n",
    "\"\"\" Reg season starts with 2, playoffs 4, pre 1 \"\"\"\n",
    "\"\"\" \n",
    "For some reason summer league and preseason games are sometimes included in reg season IDs.\n",
    "The function accounts for this by only looking at Game IDs that start with 0021 for reg reason,\n",
    "0041 for playoffs, 0011 for preseason\n",
    "\"\"\"\n",
    "\n",
    "def get_season_team(seasonID, team_id, team_names):\n",
    "    seasonID = str(seasonID)\n",
    "    gameID_prefix = seasonID[0]\n",
    "    return team_names[team_id].loc[(team_names[team_id][\"SEASON_ID\"].str.contains(seasonID)) & \\\n",
    "                                    (team_names[team_id]['GAME_ID'].str.startswith('00{0}'.format(gameID_prefix)))]\n",
    "\n",
    "\n",
    "\"\"\" gets the number of rows in the passed df\"\"\"\n",
    "def num_rows(df):\n",
    "    return len(df.index)\n",
    "\n",
    "\"\"\" returns the number of features of the df\"\"\"\n",
    "def num_features(df):\n",
    "    return len(df.columns)\n",
    "\n",
    "\"\"\" returns a list of the features from the start index moving forward. Using 9 for now \"\"\"\n",
    "def get_features(df, start_idx=9):\n",
    "    return [feature for feature in df.columns.tolist()[start_idx:]]\n",
    "\n",
    "\"\"\" \n",
    "util func: gets last n games given the curr game\n",
    "in the df with the correct season, year\n",
    "\"\"\"\n",
    "def last_n_games(df, n, curr_game):\n",
    "    n_rows = num_rows(df)\n",
    "    # the first row is the latest game. I.E for reg season it's 82nd game\n",
    "    \n",
    "\"\"\"\n",
    "returns avg team stats vector over the last n games given\n",
    "the current game. Assumes games 0 indexed\n",
    "\"\"\"\n",
    "def get_team_avgs(season_games, curr_game, n):\n",
    "    total_games = num_rows(season_games)\n",
    "    assert curr_game > n, \"curr game ({0}) > n ({1})\".format(curr_game, n)\n",
    "    assert total_games > n, \"n ({0}) is more than the total number of games ({1})\".format(n, total_games)\n",
    "    # the real index of the current game\n",
    "    game_idx = total_games - curr_game - 1\n",
    "    # start at 9th index to get meaningful stats\n",
    "    start_idx = 9\n",
    "    team_avgs = np.zeros(num_features(season_games) - start_idx)\n",
    "    for i in range(game_idx - n, game_idx):\n",
    "        game_stats = np.array(season_games.iloc[i].tolist()[start_idx:])\n",
    "        team_avgs += game_stats\n",
    "    return team_avgs / n\n",
    "\n",
    "def print_team_avgs(season_games, team_avgs):\n",
    "    features = get_features(season_games)\n",
    "    for stat, feature in zip(team_avgs, features):\n",
    "        print(\"{0}:{1}\".format(feature, stat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEST: get the 2018 season games for the Atlanta Hawks. \n",
    "\n",
    "# atl_reg_season = get_season_team(22018, 1610612737, team_names_test)\n",
    "\n",
    "# print the avgs of the 10 games before the 16th game that the Hawks played in the 2017-2018 season\n",
    "\n",
    "atl_team_avgs = get_team_avgs(atl_reg_season, 16, 10)\n",
    "#print_team_avgs(atl_reg_season, atl_team_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_opponent_id(opp_abr, season_id):\n",
    "    \n",
    "    return all_abrs[opp_abr].loc[all_abrs[opp_abr][\"SEASON_ID\"].str.contains(str(season_id))][\"TEAM_ID\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_opponent(n, curr_team, season_id):\n",
    "    full_df = get_season_team(season_id, curr_team, team_names_test).reset_index()\n",
    "    \n",
    "    df_of_game = full_df.iloc[[-(n + 1)]]\n",
    "    opp_abr = df_of_game[\"MATCHUP\"].values[0][-3::]\n",
    "    return find_opponent_id(opp_abr, season_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610612753"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST: get the opponent of the Atlanta Hawks's 2nd game of the the 2018 season\n",
    "\n",
    "find_opponent(1, 1610612737, 22019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_01s(letter):\n",
    "    return 1 if letter == \"W\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_home_team(team_df, curr_game):\n",
    "    matchup = team_df[\"MATCHUP\"].iloc[num_rows(team_df) - curr_game - 1]\n",
    "    #print('matchup: ', matchup)\n",
    "    return False if \"@\" in matchup else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" return the difference vector betweeen the current team and its opponent \"\"\"\n",
    "def find_diff_vector(curr_game, n, curr_team, season_id):\n",
    "    \n",
    "    #curr_team_season is a df\n",
    "    curr_team_season = get_season_team(season_id, curr_team, team_names_test)\n",
    "    curr_team_avgs = get_team_avgs(curr_team_season, curr_game, n)\n",
    "    \n",
    "    #check for home game\n",
    "    if check_home_team(curr_team_season, curr_game):\n",
    "    \n",
    "        # find point differentials\n",
    "        outcome = curr_team_season[\"PLUS_MINUS\"].iloc[num_rows(curr_team_season) - curr_game - 1]\n",
    "\n",
    "        opponent = find_opponent(curr_game, curr_team, season_id)\n",
    "        opponent_team_season = get_season_team(season_id, opponent, team_names_test)\n",
    "        opponent_team_avgs = get_team_avgs(opponent_team_season, curr_game, n)\n",
    "\n",
    "        # normalize \n",
    "        scaler = normalize(season_id - 1)\n",
    "        curr_team_avgs_normalized = scaler.transform([curr_team_avgs])\n",
    "        opp_team_avgs_normalized = scaler.transform([opponent_team_avgs])\n",
    "\n",
    "        diff = np.subtract(curr_team_avgs_normalized, opp_team_avgs_normalized)\n",
    "\n",
    "        return diff, outcome\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST: diff vector between Atlanta Hawks' stats and its opponents' stats on the Hawks' 16th\n",
    "# game based on the averages of the last 15 games before the nth game\"\"\"\n",
    "find_diff_vector(15, 14, 1610612737, 22018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" gets diff vectors for all the games 2-82 for given team and season\"\"\" \n",
    "def get_season_diff_vectors(curr_team, season_id):\n",
    "    diff_vector = []\n",
    "    win_losses = []\n",
    "    df_len = num_rows(get_season_team(season_id, curr_team, team_names_test))\n",
    "    for i in range(2, df_len):\n",
    "        diff, outcome = find_diff_vector(i, min(8, i-1), curr_team, season_id)\n",
    "        if outcome != None:\n",
    "            diff_vector.append(diff)\n",
    "            win_losses.append(outcome)\n",
    "    return diff_vector, win_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST: get_season_diff_vectors function\n",
    "diffs, outcomes = get_season_diff_vectors(1610612737, 22012)\n",
    "len(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get difference vectors for all teams for one season \"\"\"\n",
    "\n",
    "def diff_vectors_per_season(season_id):\n",
    "    team_per_season_dict = {}\n",
    "    outcomes_per_season_dict = {}\n",
    "    \n",
    "    for team in team_ids[\"id\"]:\n",
    "        print(team)\n",
    "        diff, outcomes = get_season_diff_vectors(team, season_id)\n",
    "        team_per_season_dict[team] = diff\n",
    "        outcomes_per_season_dict[team] = outcomes\n",
    "    \n",
    "    return team_per_season_dict, outcomes_per_season_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" get diff vectors for all seasons for all teams \"\"\"\n",
    "\n",
    "def ultimate_diff_vectors():\n",
    "    ultimate_dict = {}\n",
    "    ultimate_dict_outcomes = {}\n",
    "    seasons = list(range(22009, 22019))\n",
    "\n",
    "    for s in seasons:\n",
    "        print(s)\n",
    "        diff, outcomes = diff_vectors_per_season(s)\n",
    "        ultimate_dict[s] = diff\n",
    "        ultimate_dict_outcomes[s] = outcomes\n",
    "        \n",
    "    return ultimate_dict, ultimate_dict_outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22009\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22010\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22011\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22012\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22013\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22014\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22015\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22016\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22017\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n",
      "22018\n",
      "1610612737\n",
      "1610612738\n",
      "1610612739\n",
      "1610612740\n",
      "1610612741\n",
      "1610612742\n",
      "1610612743\n",
      "1610612744\n",
      "1610612745\n",
      "1610612746\n",
      "1610612747\n",
      "1610612748\n",
      "1610612749\n",
      "1610612750\n",
      "1610612751\n",
      "1610612752\n",
      "1610612753\n",
      "1610612754\n",
      "1610612755\n",
      "1610612756\n",
      "1610612757\n",
      "1610612758\n",
      "1610612759\n",
      "1610612760\n",
      "1610612761\n",
      "1610612762\n",
      "1610612763\n",
      "1610612764\n",
      "1610612765\n",
      "1610612766\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "key = season\n",
    "value = dictionary with key as team id, values as difference numpy arrays\n",
    "\"\"\"\n",
    "ultimate_dict_points, ultimate_dict_points_outcomes = ultimate_diff_vectors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pickle here!\"\"\"\n",
    "\n",
    "#save_obj(ultimate_dict_points, 'ultimate_dict_points')\n",
    "ultimate_dict_points_pickled = load_obj('ultimate_dict_points')\n",
    "\n",
    "#save_obj(ultimate_dict_points_outcomes, 'ultimate_dict_points_outcome')\n",
    "ultimate_dict_points_outcomes_pickled = load_obj('ultimate_dict_points_outcome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pipeline import Model\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massive_flatten(ultimate_lists):\n",
    "    flattened_values = []\n",
    "    for team in ultimate_lists.values():\n",
    "        for games in team.values():\n",
    "            flattened_values.extend(games)\n",
    "    return flattened_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def flatten_further(ult):\n",
    "    for idx, vector in enumerate(ult):\n",
    "        ult[idx] = vector.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = massive_flatten(ultimate_dict_points_pickled)\n",
    "y = massive_flatten(ultimate_dict_points_outcomes_pickled)\n",
    "# X = massive_flatten(ultimate_dict_homeOnly_pickled)\n",
    "# y = massive_flatten(ultimate_dict_homeOnly_outcomes_pickled)\n",
    "flatten_further(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(LinearRegression())\n",
    "m.train(Xtr, ytr)\n",
    "lin_preds = m.predict(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22962292623643407"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = lin_preds/yte\n",
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using point spread predictions (lin reg) to predict win/loss. About the same accuracy as directly predicting win/loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6777815583531813"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yte = np.array(yte)\n",
    "both_win = (lin_preds > 0) & (yte > 0)\n",
    "both_loss = (lin_preds < 0) & (yte < 0)\n",
    "win_loss_acc = len(np.where(both_win | both_loss)[0]) / len(yte)\n",
    "win_loss_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7133812190112241"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(Xtr, ytr)\n",
    "decision_tree.score(Xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/virtualenvir/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0816047978192056"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tree = RandomForestRegressor()\n",
    "random_tree.fit(Xtr, ytr)\n",
    "random_tree.score(Xte, yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPRegressor(solver='adam', activation='relu', alpha=5e-3,hidden_layer_sizes=(32,16),max_iter=3000, random_state=1)\n",
    "clf.fit(Xtr, ytr)\n",
    "#nn_preds = clf.predict(Xte)\n",
    "clf.score(Xte, yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Logistic Regression model to predict 2019 game outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 2\n",
      "matchup:  GSW @ NOP\n",
      "opponent: 1610612740\n",
      "matchup:  NOP @ HOU\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=None.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-6daa7de6604a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdiff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_diff_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'actual:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/School/Launchpad/BalliNN/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    263\u001b[0m                                  \"yet\" % {'name': type(self).__name__})\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    512\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=None.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# \"\"\"get the opponent of the Atlanta Hawks's 2nd game of the the 2018 season\"\"\"\n",
    "\n",
    "# find_opponent(2, 1610612737, 22018)\n",
    "\n",
    "#diff, L = find_diff_vector(5, 4, 1610612737, 22019)  \n",
    "#all_abrs['GSW']\n",
    "for i in range(2, 7):\n",
    "    print('i:', i)\n",
    "    diff, outcome = find_diff_vector(i, i-1, 1610612737 + 7, 22019)  \n",
    "    if (diff is None):\n",
    "        opponent = find_opponent(i, 1610612737 + 7, 22019)\n",
    "        print('opponent:', opponent)\n",
    "        \n",
    "        diff, outcome = find_diff_vector(i, i-1, opponent, 22019)\n",
    "    print('predicted:', m.predict(diff)[0], 'actual:', outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([128.25   ,  46.     ,  88.5    ,   0.51875,  16.5    ,  33.75   ,\n",
       "         0.48925,  19.75   ,  25.25   ,   0.79025,  10.     ,  40.5    ,\n",
       "        50.5    ,  33.25   ,   6.5    ,   6.     ,  13.25   ,  23.5    ,\n",
       "        17.     ])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = get_features(all_abrs['ATL'])\n",
    "features[9]\n",
    "season = get_season_team(22018, 1610612737 + 7, team_names_test)\n",
    "get_team_avgs(season, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117.75 ,  44.75 ,  89.25 ,   0.503,  11.75 ,  32.5  ,   0.371,\n",
       "        16.5  ,  20.5  ,   0.804,   9.75 ,  36.   ,  45.75 ,  27.25 ,\n",
       "         6.5  ,   4.75 ,  16.75 ,  21.25 ,  12.75 ])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = get_features(all_abrs['ATL'])\n",
    "features[9]\n",
    "season = get_season_team(22018, 1610612737 + 29, team_names_test)\n",
    "get_team_avgs(season, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenvir",
   "language": "python",
   "name": "virtualenvir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
